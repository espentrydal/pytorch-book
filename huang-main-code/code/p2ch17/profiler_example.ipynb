{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be4448a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "class MLPModule(torch.nn.Module):\n",
    "    def __init__(self, d_hid: int):\n",
    "        super().__init__()\n",
    "        self.net1 = torch.nn.Linear(d_hid, d_hid)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.net2 = torch.nn.Linear(d_hid, d_hid)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.net2(x)\n",
    "        return x\n",
    "\n",
    "class MultiMLP(torch.nn.Module):\n",
    "    def __init__(self, d_hid: int, n_layers: int = 10):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList([MLPModule(d_hid) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Create a model instance and some sample data\n",
    "d_hid = 1024\n",
    "model = MultiMLP(d_hid)\n",
    "input_data = torch.randn(64, d_hid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e41b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, input_data, device=\"cpu\", warmup_iters=5):\n",
    "    model = model.to(device)\n",
    "    input_data = input_data.to(device)\n",
    "    # Warm-up iterations\n",
    "    for _ in range(warmup_iters):\n",
    "        with torch.no_grad():\n",
    "            _ = model(input_data)\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    activities = [ProfilerActivity.CPU]\n",
    "    if device == \"cuda\":\n",
    "        activities.append(ProfilerActivity.CUDA)\n",
    "    with profile(\n",
    "        activities=activities,\n",
    "    ) as prof:\n",
    "        output = model(input_data)\n",
    "\n",
    "    display = prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10)\n",
    "    prof.export_chrome_trace(\"trace.json\")\n",
    "    return display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d094975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "          aten::linear         0.79%     151.499us        87.05%      16.673ms     833.636us            20  \n",
      "           aten::addmm        65.43%      12.531ms        84.09%      16.105ms     805.236us            20  \n",
      "           aten::copy_        18.10%       3.466ms        18.10%       3.466ms     173.299us            20  \n",
      "            aten::relu         1.27%     242.700us        12.95%       2.480ms     247.959us            10  \n",
      "       aten::clamp_min        11.68%       2.237ms        11.68%       2.237ms     223.689us            10  \n",
      "               aten::t         1.45%     277.794us         2.17%     416.493us      20.825us            20  \n",
      "       aten::transpose         0.38%      73.099us         0.72%     138.699us       6.935us            20  \n",
      "          aten::expand         0.36%      68.300us         0.49%      93.700us       4.685us            20  \n",
      "      aten::as_strided         0.48%      91.000us         0.48%      91.000us       2.275us            40  \n",
      "    aten::resolve_conj         0.07%      14.300us         0.07%      14.300us       0.357us            40  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 19.152ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_model(model, input_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bf84df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        aten::linear        10.60%     486.700us        89.74%       4.119ms     205.965us     258.000us         4.50%       5.542ms     277.100us            20  \n",
      "         aten::addmm        43.10%       1.978ms        57.30%       2.630ms     131.520us       2.244ms        39.14%       3.117ms     155.850us            20  \n",
      "             aten::t        13.64%     626.100us        21.83%       1.002ms      50.110us     242.000us         4.22%       2.167ms     108.350us            20  \n",
      "         aten::empty        14.21%     652.100us        14.21%     652.100us      32.605us     873.000us        15.23%     873.000us      43.650us            20  \n",
      "          aten::relu         6.34%     290.900us        10.26%     470.900us      47.090us      70.000us         1.22%     191.000us      19.100us            10  \n",
      "     aten::transpose         7.53%     345.500us         8.19%     376.100us      18.805us       1.840ms        32.09%       1.925ms      96.250us            20  \n",
      "     aten::clamp_min         3.92%     180.000us         3.92%     180.000us      18.000us     121.000us         2.11%     121.000us      12.100us            10  \n",
      "    aten::as_strided         0.67%      30.600us         0.67%      30.600us       1.530us      85.000us         1.48%      85.000us       4.250us            20  \n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.590ms\n",
      "Self CUDA time total: 5.733ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_model(model, input_data, device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fd05f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import types\n",
    "\n",
    "new_model = copy.deepcopy(model)\n",
    "def new_forward(self, x):\n",
    "    for i, layer in enumerate(self.layers):\n",
    "        with record_function(f\"Layer {i} Forward\"):\n",
    "            x = layer(x)\n",
    "    return x\n",
    "\n",
    "new_model.forward = types.MethodType(new_forward, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af5748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "        aten::linear        15.59%     972.000us        65.91%       4.108ms     205.400us     429.000us         6.63%       5.737ms     286.850us            20  \n",
      "     Layer 6 Forward         7.85%     489.400us        37.51%       2.338ms       2.338ms      10.000us         0.15%     352.000us     352.000us             1  \n",
      "         aten::addmm        25.77%       1.606ms        26.87%       1.675ms      83.750us       3.725ms        57.58%       3.917ms     195.850us            20  \n",
      "             aten::t        12.14%     756.600us        23.44%       1.461ms      73.050us     509.000us         7.87%       1.391ms      69.550us            20  \n",
      "     aten::transpose        10.83%     674.900us        11.30%     704.400us      35.220us     642.000us         9.92%     882.000us      44.100us            20  \n",
      "          aten::relu         6.37%     397.000us        10.13%     631.700us      63.170us     145.000us         2.24%     334.000us      33.400us            10  \n",
      "     Layer 8 Forward         2.82%     175.600us         9.93%     619.000us     619.000us     121.000us         1.87%     625.000us     625.000us             1  \n",
      "     Layer 5 Forward         1.74%     108.400us         8.41%     524.300us     524.300us       9.000us         0.14%     356.000us     356.000us             1  \n",
      "     Layer 7 Forward         2.11%     131.500us         7.97%     496.600us     496.600us      71.000us         1.10%     502.000us     502.000us             1  \n",
      "     Layer 0 Forward         1.75%     109.300us         6.70%     417.700us     417.700us      10.000us         0.15%       2.549ms       2.549ms             1  \n",
      "--------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 6.233ms\n",
      "Self CUDA time total: 6.469ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_model(new_model, input_data, device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cca5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = torch.compile(model)\n",
    "print(run_model(compiled_model, input_data, device='cuda'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
